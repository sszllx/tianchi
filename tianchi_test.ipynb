{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijing/.local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tools.data_tools import get_files, read_file\n",
    "\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = get_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BalanceSheet-Bank.csv': '/home/lijing/.keras/fddc2018-01/BalanceSheet-Bank.csv',\n",
       " 'BalanceSheet-GeneralBusiness.csv': '/home/lijing/.keras/fddc2018-01/BalanceSheet-GeneralBusiness.csv',\n",
       " 'BalanceSheet-Insurance.csv': '/home/lijing/.keras/fddc2018-01/BalanceSheet-Insurance.csv',\n",
       " 'BalanceSheet-Securities.csv': '/home/lijing/.keras/fddc2018-01/BalanceSheet-Securities.csv',\n",
       " 'CashFlowStatement-Bank.csv': '/home/lijing/.keras/fddc2018-01/CashFlowStatement-Bank.csv',\n",
       " 'CashFlowStatement-GeneralBusiness.csv': '/home/lijing/.keras/fddc2018-01/CashFlowStatement-GeneralBusiness.csv',\n",
       " 'CashFlowStatement-Insurance.csv': '/home/lijing/.keras/fddc2018-01/CashFlowStatement-Insurance.csv',\n",
       " 'CashFlowStatement-Securities.csv': '/home/lijing/.keras/fddc2018-01/CashFlowStatement-Securities.csv',\n",
       " 'CompanyOperation.csv': '/home/lijing/.keras/fddc2018-01/CompanyOperation.csv',\n",
       " 'IncomeStatement-Bank.csv': '/home/lijing/.keras/fddc2018-01/IncomeStatement-Bank.csv',\n",
       " 'IncomeStatement-GeneralBusiness.csv': '/home/lijing/.keras/fddc2018-01/IncomeStatement-GeneralBusiness.csv',\n",
       " 'IncomeStatement-Insurance.csv': '/home/lijing/.keras/fddc2018-01/IncomeStatement-Insurance.csv',\n",
       " 'IncomeStatement-Securities.csv': '/home/lijing/.keras/fddc2018-01/IncomeStatement-Securities.csv',\n",
       " 'MacroIndustry.csv': '/home/lijing/.keras/fddc2018-01/MacroIndustry.csv',\n",
       " 'MarketData.csv': '/home/lijing/.keras/fddc2018-01/MarketData.csv'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename, flist, ticker_symbol, report_type):\n",
    "    dataframe = read_file(filename)\n",
    "#     dataframe = dataframe[dataframe['TICKER_SYMBOL'] == ticker_symbol][flist].sort_values(by='END_DATE')\n",
    "    dataframe = dataframe[flist].sort_values(by='PUBLISH_DATE')\n",
    "    dataframe = dataframe.drop_duplicates(subset=['TICKER_SYMBOL','END_DATE'], keep='last').reset_index(drop=True)\n",
    "    dataframe = dataframe[dataframe['REPORT_TYPE'] == report_type]\n",
    "    dataframe = dataframe.set_index('TICKER_SYMBOL')\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs_data = get_data('CashFlowStatement-GeneralBusiness.csv',\n",
    "                   ['TICKER_SYMBOL', 'REPORT_TYPE', 'PUBLISH_DATE',\n",
    "                    'END_DATE', 'C_FR_SALE_G_S',\n",
    "                    'N_CHANGE_IN_CASH', 'N_CE_BEG_BAL', 'N_CE_END_BAL'],\n",
    "                    '000002', 'S1').drop(['REPORT_TYPE', 'PUBLISH_DATE'],axis=1).fillna(method='ffill').fillna(method='bfill')\n",
    "bs_data = get_data('BalanceSheet-GeneralBusiness.csv',\n",
    "                  ['TICKER_SYMBOL', 'REPORT_TYPE', 'PUBLISH_DATE',\n",
    "                   'END_DATE', 'CASH_C_EQUIV',\n",
    "                   'T_EQUITY_ATTR_P', 'MINORITY_INT', 'T_SH_EQUITY',\n",
    "                   'T_LIAB_EQUITY'],\n",
    "                   '000002', 'S1').drop(['REPORT_TYPE', 'PUBLISH_DATE'],axis=1).fillna(method='ffill').fillna(method='bfill')\n",
    "is_data = get_data('IncomeStatement-GeneralBusiness.csv',\n",
    "                  ['TICKER_SYMBOL', 'END_DATE', 'REPORT_TYPE', 'PUBLISH_DATE', 'REVENUE'],\n",
    "                  '000002', 'S1').drop(['REPORT_TYPE', 'PUBLISH_DATE'],axis=1).fillna(method='ffill').fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (cfs_data['END_DATE'] >= '2008-01-01') & (cfs_data['END_DATE'] <= '2016-06-30')\n",
    "train_cfs_data = cfs_data.loc[mask]\n",
    "mask = (bs_data['END_DATE'] >= '2008-01-01') & (bs_data['END_DATE'] <= '2016-06-30')\n",
    "train_bs_data = bs_data.loc[mask]\n",
    "mask = (is_data['END_DATE'] >= '2008-01-01') & (is_data['END_DATE'] <= '2016-06-30')\n",
    "train_is_data = is_data.loc[mask]\n",
    "\n",
    "mask = (cfs_data['END_DATE'] == '2017-06-30')\n",
    "test_cfs_data = cfs_data.loc[mask]\n",
    "mask = (bs_data['END_DATE'] == '2017-06-30')\n",
    "test_bs_data = bs_data.loc[mask]\n",
    "mask = (is_data['END_DATE'] == '2017-06-30')\n",
    "test_is_data = is_data.loc[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = (bs_data['END_DATE'] == '2009-06-30')\n",
    "tmp_data = bs_data.loc[mask]\n",
    "tmp_data['END_DATE'] = pd.to_datetime('2008-06-30')\n",
    "\n",
    "train_bs_data = train_bs_data.append(tmp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from 2008-06-30 ~ 2016-06-30 target\n",
    "y = train_is_data.drop('END_DATE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create train data\n",
    "# train_data = train_cfs_data.drop('END_DATE', axis=1)\n",
    "# train_data = train_data.join(train_bs_data.drop('END_DATE', axis=1))\n",
    "# train_data = train_data.join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create train data\n",
    "# train_data = train_cfs_data\n",
    "train_data = pd.merge(train_cfs_data, train_bs_data, on=['TICKER_SYMBOL', 'END_DATE'])\n",
    "train_data = pd.merge(train_data, train_is_data, on=['TICKER_SYMBOL', 'END_DATE'])\n",
    "train_data = train_data.fillna(method='ffill')\n",
    "train_data = train_data.drop('END_DATE', axis=1)\n",
    "\n",
    "test_data = pd.merge(test_cfs_data, test_bs_data, on=['TICKER_SYMBOL', 'END_DATE'])\n",
    "test_data = test_data.drop('END_DATE', axis=1)\n",
    "test_data = test_data.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# colormap = plt.cm.RdBu\n",
    "# plt.figure(figsize=(14,12))\n",
    "# plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "# sns.heatmap(train_data.astype(float).corr(),linewidths=0.1,vmax=1.0, \n",
    "#             square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'the label [002248] is not in the [index]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1789\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m                     \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36merror\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1784\u001b[0m                                .format(key=key,\n\u001b[0;32m-> 1785\u001b[0;31m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'the label [002248] is not in the [index]'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-279-077b2ead6e08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'002248'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'002248'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1796\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m                 \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36merror\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 raise KeyError(u\"the label [{key}] is not in the [{axis}]\"\n\u001b[1;32m   1784\u001b[0m                                .format(key=key,\n\u001b[0;32m-> 1785\u001b[0;31m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'the label [002248] is not in the [index]'"
     ]
    }
   ],
   "source": [
    "train_data = train_data.loc['002248']\n",
    "test_data = test_data.loc['002248']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['REVENUE'].ravel()\n",
    "train = train_data.drop(['REVENUE'], axis=1)\n",
    "x_train = train.values # Creates an array of the train data\n",
    "x_test = test_data.values.reshape(1, -1) # Creats an array of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.43364923e+08, 3.24277116e+08, 3.24604772e+08, 2.57743443e+08,\n",
       "       1.63559419e+08, 1.76718896e+08, 9.01336306e+07, 7.96464026e+07])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = train_data.shape[0]\n",
    "ntest = test_data.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 4 # set folds for out-of-fold prediction\n",
    "kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n",
    "\n",
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train.astype('int'))\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':500,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.75\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 objects that represent our 4 models\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijing/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:305: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "/home/lijing/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:305: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "/home/lijing/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:305: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\n",
    "rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\n",
    "ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \n",
    "gb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost \n",
    "svc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test) # Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.43364923e+08, 3.24277116e+08, 3.24604772e+08, 2.57743443e+08,\n",
       "       1.63559419e+08, 1.76718896e+08, 9.01336306e+07, 7.96464026e+07])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijing/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:305: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.075 0.08  0.064 0.105 0.102 0.073 0.079 0.075 0.105]\n",
      "[0.098      0.12466667 0.10666667 0.09933333 0.10133333 0.069\n",
      " 0.15766667 0.096      0.08733333]\n",
      "[0.096 0.092 0.062 0.066 0.084 0.274 0.158 0.05  0.118]\n",
      "[0.01483672 0.01617266 0.01288774 0.01445264 0.0214124  0.02539216\n",
      " 0.01315866 0.00920841 0.01322859]\n"
     ]
    }
   ],
   "source": [
    "rf_feature = rf.feature_importances(x_train,y_train.astype('int'))\n",
    "et_feature = et.feature_importances(x_train, y_train.astype('int'))\n",
    "ada_feature = ada.feature_importances(x_train, y_train.astype('int'))\n",
    "gb_feature = gb.feature_importances(x_train,y_train.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_features = [0.075, 0.08,  0.064, 0.105, 0.102, 0.073, 0.079, 0.075, 0.105]\n",
    "et_features = [0.098,      0.12466667, 0.10666667, 0.09933333, 0.10133333, 0.069,\n",
    " 0.15766667, 0.096,      0.08733333]\n",
    "ada_features = [0.096, 0.092, 0.062, 0.066, 0.084, 0.274, 0.158, 0.05,  0.118]\n",
    "gb_features = [0.01483672, 0.01617266, 0.01288774, 0.01445264, 0.0214124,  0.02539216,\n",
    " 0.01315866, 0.00920841, 0.01322859]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train.columns.values\n",
    "# Create a dataframe with features\n",
    "feature_dataframe = pd.DataFrame( {'features': cols,\n",
    "     'Random Forest feature importances': rf_features,\n",
    "     'Extra Trees  feature importances': et_features,\n",
    "      'AdaBoost feature importances': ada_features,\n",
    "    'Gradient Boost feature importances': gb_features\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>Random Forest feature importances</th>\n",
       "      <th>Extra Trees  feature importances</th>\n",
       "      <th>AdaBoost feature importances</th>\n",
       "      <th>Gradient Boost feature importances</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_FR_SALE_G_S</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>0.070959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N_CHANGE_IN_CASH</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.124667</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.016173</td>\n",
       "      <td>0.078210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N_CE_BEG_BAL</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.012888</td>\n",
       "      <td>0.061389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           features  Random Forest feature importances  \\\n",
       "0     C_FR_SALE_G_S                              0.075   \n",
       "1  N_CHANGE_IN_CASH                              0.080   \n",
       "2      N_CE_BEG_BAL                              0.064   \n",
       "\n",
       "   Extra Trees  feature importances  AdaBoost feature importances  \\\n",
       "0                          0.098000                         0.096   \n",
       "1                          0.124667                         0.092   \n",
       "2                          0.106667                         0.062   \n",
       "\n",
       "   Gradient Boost feature importances      mean  \n",
       "0                            0.014837  0.070959  \n",
       "1                            0.016173  0.078210  \n",
       "2                            0.012888  0.061389  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the new column containing the average of values\n",
    "\n",
    "feature_dataframe['mean'] = feature_dataframe.mean(axis= 1) # axis = 1 computes the mean row-wise\n",
    "feature_dataframe.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>GradientBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79646402.0</td>\n",
       "      <td>324604772.0</td>\n",
       "      <td>79646402.0</td>\n",
       "      <td>79646402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324604772.0</td>\n",
       "      <td>324604772.0</td>\n",
       "      <td>324604772.0</td>\n",
       "      <td>324604772.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324277115.0</td>\n",
       "      <td>324277115.0</td>\n",
       "      <td>90133630.0</td>\n",
       "      <td>324277115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243364923.0</td>\n",
       "      <td>176718895.0</td>\n",
       "      <td>163559418.0</td>\n",
       "      <td>176718895.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>243364923.0</td>\n",
       "      <td>257743443.0</td>\n",
       "      <td>90133630.0</td>\n",
       "      <td>257743443.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RandomForest   ExtraTrees     AdaBoost  GradientBoost\n",
       "0    79646402.0  324604772.0   79646402.0     79646402.0\n",
       "1   324604772.0  324604772.0  324604772.0    324604772.0\n",
       "2   324277115.0  324277115.0   90133630.0    324277115.0\n",
       "3   243364923.0  176718895.0  163559418.0    176718895.0\n",
       "4   243364923.0  257743443.0   90133630.0    257743443.0"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train.ravel(),\n",
    "     'ExtraTrees': et_oof_train.ravel(),\n",
    "     'AdaBoost': ada_oof_train.ravel(),\n",
    "      'GradientBoost': gb_oof_train.ravel()\n",
    "    })\n",
    "base_predictions_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train, svc_oof_train), axis=1)\n",
    "x_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, svc_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijing/.local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning:\n",
      "\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier(\n",
    "    #learning_rate = 0.02,\n",
    " n_estimators= 2000,\n",
    " max_depth= 4,\n",
    " min_child_weight= 2,\n",
    " #gamma=1,\n",
    " gamma=0.9,                        \n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread= -1,\n",
    " scale_pos_weight=1).fit(x_train, y_train)\n",
    "predictions = gbm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_data = get_data('IncomeStatement-GeneralBusiness.csv',\n",
    "                  ['TICKER_SYMBOL','PUBLISH_DATE', 'END_DATE', 'REPORT_TYPE', 'REVENUE'],\n",
    "                  '000002', 'S1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUBLISH_DATE</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>REPORT_TYPE</th>\n",
       "      <th>REVENUE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TICKER_SYMBOL</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2009-07-10</td>\n",
       "      <td>2008-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>1.976248e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2010-07-23</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>2.433649e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2011-08-18</td>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>3.242771e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2011-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>3.246048e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2013-08-27</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>2.577434e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2014-08-28</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>1.635594e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2015-08-29</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>1.767189e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2016-08-26</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>9.013363e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>7.964640e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>2017-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>6.332250e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PUBLISH_DATE   END_DATE REPORT_TYPE       REVENUE\n",
       "TICKER_SYMBOL                                                  \n",
       "002248          2009-07-10 2008-06-30          S1  1.976248e+08\n",
       "002248          2010-07-23 2009-06-30          S1  2.433649e+08\n",
       "002248          2011-08-18 2010-06-30          S1  3.242771e+08\n",
       "002248          2012-07-31 2011-06-30          S1  3.246048e+08\n",
       "002248          2013-08-27 2012-06-30          S1  2.577434e+08\n",
       "002248          2014-08-28 2013-06-30          S1  1.635594e+08\n",
       "002248          2015-08-29 2014-06-30          S1  1.767189e+08\n",
       "002248          2016-08-26 2015-06-30          S1  9.013363e+07\n",
       "002248          2017-08-25 2016-06-30          S1  7.964640e+07\n",
       "002248          2017-08-25 2017-06-30          S1  6.332250e+07"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_data.loc['002248']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
