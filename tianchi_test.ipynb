{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tools.data_tools import get_files, read_file\n",
    "\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import cross_validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = get_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BalanceSheet-Bank.csv': '/home/lijing/.keras/fddc2018-01/BalanceSheet-Bank.csv',\n",
       " 'BalanceSheet-GeneralBusiness.csv': '/home/lijing/.keras/fddc2018-01/BalanceSheet-GeneralBusiness.csv',\n",
       " 'BalanceSheet-Insurance.csv': '/home/lijing/.keras/fddc2018-01/BalanceSheet-Insurance.csv',\n",
       " 'BalanceSheet-Securities.csv': '/home/lijing/.keras/fddc2018-01/BalanceSheet-Securities.csv',\n",
       " 'CashFlowStatement-Bank.csv': '/home/lijing/.keras/fddc2018-01/CashFlowStatement-Bank.csv',\n",
       " 'CashFlowStatement-GeneralBusiness.csv': '/home/lijing/.keras/fddc2018-01/CashFlowStatement-GeneralBusiness.csv',\n",
       " 'CashFlowStatement-Insurance.csv': '/home/lijing/.keras/fddc2018-01/CashFlowStatement-Insurance.csv',\n",
       " 'CashFlowStatement-Securities.csv': '/home/lijing/.keras/fddc2018-01/CashFlowStatement-Securities.csv',\n",
       " 'CompanyOperation.csv': '/home/lijing/.keras/fddc2018-01/CompanyOperation.csv',\n",
       " 'IncomeStatement-Bank.csv': '/home/lijing/.keras/fddc2018-01/IncomeStatement-Bank.csv',\n",
       " 'IncomeStatement-GeneralBusiness.csv': '/home/lijing/.keras/fddc2018-01/IncomeStatement-GeneralBusiness.csv',\n",
       " 'IncomeStatement-Insurance.csv': '/home/lijing/.keras/fddc2018-01/IncomeStatement-Insurance.csv',\n",
       " 'IncomeStatement-Securities.csv': '/home/lijing/.keras/fddc2018-01/IncomeStatement-Securities.csv',\n",
       " 'MacroIndustry.csv': '/home/lijing/.keras/fddc2018-01/MacroIndustry.csv',\n",
       " 'MarketData.csv': '/home/lijing/.keras/fddc2018-01/MarketData.csv'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename, flist, ticker_symbol, report_type):\n",
    "    dataframe = read_file(filename)\n",
    "#     dataframe = dataframe[dataframe['TICKER_SYMBOL'] == ticker_symbol][flist].sort_values(by='END_DATE')\n",
    "    dataframe = dataframe[flist].sort_values(by='PUBLISH_DATE')\n",
    "    dataframe = dataframe.drop_duplicates(subset=['TICKER_SYMBOL','END_DATE'], keep='last').reset_index(drop=True)\n",
    "    dataframe = dataframe[dataframe['REPORT_TYPE'] == report_type]\n",
    "    dataframe = dataframe.set_index('TICKER_SYMBOL')\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs_data = get_data('CashFlowStatement-GeneralBusiness.csv',\n",
    "                   ['TICKER_SYMBOL', 'REPORT_TYPE', 'PUBLISH_DATE',\n",
    "                    'END_DATE', 'C_FR_SALE_G_S',\n",
    "                    'N_CHANGE_IN_CASH', 'N_CE_BEG_BAL', 'N_CE_END_BAL'],\n",
    "                    '000002', 'S1').drop(['REPORT_TYPE', 'PUBLISH_DATE'],axis=1).fillna(method='ffill').fillna(method='bfill')\n",
    "bs_data = get_data('BalanceSheet-GeneralBusiness.csv',\n",
    "                  ['TICKER_SYMBOL', 'REPORT_TYPE', 'PUBLISH_DATE',\n",
    "                   'END_DATE', 'CASH_C_EQUIV',\n",
    "                   'T_EQUITY_ATTR_P', 'MINORITY_INT', 'T_SH_EQUITY',\n",
    "                   'T_LIAB_EQUITY'],\n",
    "                   '000002', 'S1').drop(['REPORT_TYPE', 'PUBLISH_DATE'],axis=1).fillna(method='ffill').fillna(method='bfill')\n",
    "is_data = get_data('IncomeStatement-GeneralBusiness.csv',\n",
    "                  ['TICKER_SYMBOL', 'END_DATE', 'REPORT_TYPE', 'PUBLISH_DATE', 'REVENUE'],\n",
    "                  '000002', 'S1').drop(['REPORT_TYPE', 'PUBLISH_DATE'],axis=1).fillna(method='ffill').fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (cfs_data['END_DATE'] >= '2008-01-01') & (cfs_data['END_DATE'] <= '2016-06-30')\n",
    "train_cfs_data = cfs_data.loc[mask]\n",
    "mask = (bs_data['END_DATE'] >= '2008-01-01') & (bs_data['END_DATE'] <= '2016-06-30')\n",
    "train_bs_data = bs_data.loc[mask]\n",
    "mask = (is_data['END_DATE'] >= '2008-01-01') & (is_data['END_DATE'] <= '2016-06-30')\n",
    "train_is_data = is_data.loc[mask]\n",
    "\n",
    "mask = (cfs_data['END_DATE'] == '2017-06-30')\n",
    "test_cfs_data = cfs_data.loc[mask]\n",
    "mask = (bs_data['END_DATE'] == '2017-06-30')\n",
    "test_bs_data = bs_data.loc[mask]\n",
    "mask = (is_data['END_DATE'] == '2017-06-30')\n",
    "test_is_data = is_data.loc[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = (bs_data['END_DATE'] == '2009-06-30')\n",
    "tmp_data = bs_data.loc[mask]\n",
    "tmp_data['END_DATE'] = pd.to_datetime('2008-06-30')\n",
    "\n",
    "train_bs_data = train_bs_data.append(tmp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from 2008-06-30 ~ 2016-06-30 target\n",
    "y = train_is_data.drop('END_DATE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create train data\n",
    "# train_data = train_cfs_data.drop('END_DATE', axis=1)\n",
    "# train_data = train_data.join(train_bs_data.drop('END_DATE', axis=1))\n",
    "# train_data = train_data.join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create train data\n",
    "# train_data = train_cfs_data\n",
    "train_data = pd.merge(train_cfs_data, train_bs_data, on=['TICKER_SYMBOL', 'END_DATE'])\n",
    "train_data = pd.merge(train_data, train_is_data, on=['TICKER_SYMBOL', 'END_DATE'])\n",
    "train_data = train_data.fillna(method='ffill')\n",
    "train_data = train_data.drop('END_DATE', axis=1)\n",
    "\n",
    "test_data = pd.merge(test_cfs_data, test_bs_data, on=['TICKER_SYMBOL', 'END_DATE'])\n",
    "test_data = test_data.drop('END_DATE', axis=1)\n",
    "test_data = test_data.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# colormap = plt.cm.RdBu\n",
    "# plt.figure(figsize=(14,12))\n",
    "# plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "# sns.heatmap(train_data.astype(float).corr(),linewidths=0.1,vmax=1.0, \n",
    "#             square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.loc['002248']\n",
    "test_data = test_data.loc['002248']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['REVENUE'].ravel()\n",
    "train = train_data.drop(['REVENUE'], axis=1)\n",
    "x_train = train.values # Creates an array of the train data\n",
    "x_test = test_data.values.reshape(1, -1) # Creats an array of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9,), (9, 9), (1, 9))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = train_data.shape[0]\n",
    "ntest = test_data.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n",
    "\n",
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train.astype('int'))\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        print(train_index, test_index)\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5 6 7 8] [0 1]\n",
      "[0 1 4 5 6 7 8] [2 3]\n",
      "[0 1 2 3 6 7 8] [4 5]\n",
      "[0 1 2 3 4 5 8] [6 7]\n",
      "[0 1 2 3 4 5 6 7] [8]\n"
     ]
    }
   ],
   "source": [
    "rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':500,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.75\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 objects that represent our 4 models\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijing/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:305: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "/home/lijing/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:305: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "/home/lijing/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:305: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\n",
    "rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\n",
    "ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \n",
    "gb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost \n",
    "svc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test) # Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.97624810e+08, 2.43364923e+08, 3.24277116e+08, 3.24604772e+08,\n",
       "       2.57743443e+08, 1.63559419e+08, 1.76718896e+08, 9.01336306e+07,\n",
       "       7.96464026e+07])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijing/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:305: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.075 0.08  0.064 0.105 0.102 0.073 0.079 0.075 0.105]\n",
      "[0.086      0.11566667 0.094      0.093      0.07766667 0.126\n",
      " 0.13066667 0.127      0.14      ]\n",
      "[0.272 0.078 0.114 0.082 0.062 0.11  0.144 0.048 0.09 ]\n",
      "[0.02170417 0.02463984 0.01614292 0.01475017 0.01254603 0.0186377\n",
      " 0.00669978 0.00991712 0.00985116]\n"
     ]
    }
   ],
   "source": [
    "rf_feature = rf.feature_importances(x_train,y_train.astype('int'))\n",
    "et_feature = et.feature_importances(x_train, y_train.astype('int'))\n",
    "ada_feature = ada.feature_importances(x_train, y_train.astype('int'))\n",
    "gb_feature = gb.feature_importances(x_train,y_train.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_features = [0.075, 0.08,  0.064, 0.105, 0.102, 0.073, 0.079, 0.075, 0.105]\n",
    "et_features = [0.086 ,     0.11566667, 0.094    ,  0.093   ,   0.07766667, 0.126,\n",
    " 0.13066667, 0.127     , 0.14      ]\n",
    "ada_features = [0.272 ,0.078, 0.114, 0.082, 0.062, 0.11,  0.144, 0.048, 0.09 ]\n",
    "gb_features = [0.02170417, 0.02463984 ,0.01614292, 0.01475017 ,0.01254603, 0.0186377,\n",
    " 0.00669978, 0.00991712, 0.00985116]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train.columns.values\n",
    "# Create a dataframe with features\n",
    "feature_dataframe = pd.DataFrame( {'features': cols,\n",
    "     'Random Forest feature importances': rf_features,\n",
    "     'Extra Trees  feature importances': et_features,\n",
    "      'AdaBoost feature importances': ada_features,\n",
    "    'Gradient Boost feature importances': gb_features\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>Random Forest feature importances</th>\n",
       "      <th>Extra Trees  feature importances</th>\n",
       "      <th>AdaBoost feature importances</th>\n",
       "      <th>Gradient Boost feature importances</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_FR_SALE_G_S</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.021704</td>\n",
       "      <td>0.113676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N_CHANGE_IN_CASH</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.115667</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.024640</td>\n",
       "      <td>0.074577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N_CE_BEG_BAL</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.016143</td>\n",
       "      <td>0.072036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           features  Random Forest feature importances  \\\n",
       "0     C_FR_SALE_G_S                              0.075   \n",
       "1  N_CHANGE_IN_CASH                              0.080   \n",
       "2      N_CE_BEG_BAL                              0.064   \n",
       "\n",
       "   Extra Trees  feature importances  AdaBoost feature importances  \\\n",
       "0                          0.086000                         0.272   \n",
       "1                          0.115667                         0.078   \n",
       "2                          0.094000                         0.114   \n",
       "\n",
       "   Gradient Boost feature importances      mean  \n",
       "0                            0.021704  0.113676  \n",
       "1                            0.024640  0.074577  \n",
       "2                            0.016143  0.072036  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the new column containing the average of values\n",
    "\n",
    "feature_dataframe['mean'] = feature_dataframe.mean(axis= 1) # axis = 1 computes the mean row-wise\n",
    "feature_dataframe.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>GradientBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79646402.0</td>\n",
       "      <td>79646402.0</td>\n",
       "      <td>79646402.0</td>\n",
       "      <td>79646402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79646402.0</td>\n",
       "      <td>324604772.0</td>\n",
       "      <td>79646402.0</td>\n",
       "      <td>79646402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324604772.0</td>\n",
       "      <td>324604772.0</td>\n",
       "      <td>324604772.0</td>\n",
       "      <td>324604772.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>324277115.0</td>\n",
       "      <td>324277115.0</td>\n",
       "      <td>90133630.0</td>\n",
       "      <td>324277115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>243364923.0</td>\n",
       "      <td>176718895.0</td>\n",
       "      <td>176718895.0</td>\n",
       "      <td>176718895.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RandomForest   ExtraTrees     AdaBoost  GradientBoost\n",
       "0    79646402.0   79646402.0   79646402.0     79646402.0\n",
       "1    79646402.0  324604772.0   79646402.0     79646402.0\n",
       "2   324604772.0  324604772.0  324604772.0    324604772.0\n",
       "3   324277115.0  324277115.0   90133630.0    324277115.0\n",
       "4   243364923.0  176718895.0  176718895.0    176718895.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train.ravel(),\n",
    "     'ExtraTrees': et_oof_train.ravel(),\n",
    "     'AdaBoost': ada_oof_train.ravel(),\n",
    "      'GradientBoost': gb_oof_train.ravel()\n",
    "    })\n",
    "base_predictions_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train, svc_oof_train), axis=1)\n",
    "x_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, svc_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijing/.local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning:\n",
      "\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier(\n",
    "    #learning_rate = 0.02,\n",
    " n_estimators= 2000,\n",
    " max_depth= 4,\n",
    " min_child_weight= 2,\n",
    " #gamma=1,\n",
    " gamma=0.9,                        \n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread= -1,\n",
    " scale_pos_weight=1).fit(x_train, y_train)\n",
    "predictions = gbm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([79646402.56])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_data = get_data('IncomeStatement-GeneralBusiness.csv',\n",
    "                  ['TICKER_SYMBOL','PUBLISH_DATE', 'END_DATE', 'REPORT_TYPE', 'REVENUE'],\n",
    "                  '000002', 'S1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUBLISH_DATE</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>REPORT_TYPE</th>\n",
       "      <th>REVENUE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TICKER_SYMBOL</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2009-07-10</td>\n",
       "      <td>2008-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>1.976248e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2010-07-23</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>2.433649e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2011-08-18</td>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>3.242771e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2011-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>3.246048e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2013-08-27</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>2.577434e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2014-08-28</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>1.635594e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2015-08-29</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>1.767189e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2016-08-26</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>9.013363e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>7.964640e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002248</th>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>2017-06-30</td>\n",
       "      <td>S1</td>\n",
       "      <td>6.332250e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PUBLISH_DATE   END_DATE REPORT_TYPE       REVENUE\n",
       "TICKER_SYMBOL                                                  \n",
       "002248          2009-07-10 2008-06-30          S1  1.976248e+08\n",
       "002248          2010-07-23 2009-06-30          S1  2.433649e+08\n",
       "002248          2011-08-18 2010-06-30          S1  3.242771e+08\n",
       "002248          2012-07-31 2011-06-30          S1  3.246048e+08\n",
       "002248          2013-08-27 2012-06-30          S1  2.577434e+08\n",
       "002248          2014-08-28 2013-06-30          S1  1.635594e+08\n",
       "002248          2015-08-29 2014-06-30          S1  1.767189e+08\n",
       "002248          2016-08-26 2015-06-30          S1  9.013363e+07\n",
       "002248          2017-08-25 2016-06-30          S1  7.964640e+07\n",
       "002248          2017-08-25 2017-06-30          S1  6.332250e+07"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_data.loc['002248']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
